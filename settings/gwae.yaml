model_name: gwae
hyperparameters:
  lr: 1e-4
  z_dim: 64
  coef_w: 1
  coef_d: 1
  coef_qentropy: 0.03
  sampler_type: neural
  merged_condition: true
  lr_disc: 1e-4
  coef_gp: 10
  times_d_training: 5
  batchnorm: false
  resblock: false
  distance_coef_initial: 2.5
dataset: mnist      #celeba
logger_path: runs/mnist_gwae    #runs/celeba_gwae
batch_size: 64
cuda_sync: false
very_verbose: true
until_convergence: true
patience: 10
